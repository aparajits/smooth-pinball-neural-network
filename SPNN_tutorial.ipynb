{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Smooth Pinball Neural Network (SPNN) Tutorial**\n",
    "## By Kostas Hatalis\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is tutorial Python code on how to use a SPNN as defined in \n",
    "\n",
    "**Hatalis, Kostas, et al. \"A Novel Smoothed Loss and Penalty Function for Noncrossing Composite Quantile Estimation via Deep Neural Networks.\" *arXiv preprint* (2019).**\n",
    "\n",
    "An SPNN is a variant of a Quantile Regression Neural Network (QRNN) with a novel smooth loss and penalty function for composite noncrossing quantile estimation. Here SPNN is presented with a single hidden layer, but more layers can be added to create a deep neural network. The smooth loss function can also be applied to convolutional and recurrent architectures.\n",
    "\n",
    "The example in this Notebook uses data from the Globel Energy Forecasting Competition 2014. The data is in the format of wind speeds, resolution of 1 hour, over 2 years (2012-2013). Training is conducted on all of the data in 2012. Testing can be conducted to predict any month in 2013. Prediction is in the form of quantiles which can be used to construct prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense \n",
    "from keras import backend as K\n",
    "K.set_floatx('float64')\n",
    "\n",
    "from pinball_loss import pinball_loss\n",
    "from load_data import load_data\n",
    "from feature_engineering import feature_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define experiment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = {\n",
    "    'tau': np.arange(0.05, 1.0, 0.05)  # quantile coverage level\n",
    "}\n",
    "experiment = load_data(experiment) #load in data\n",
    "experiment = feature_engineering(experiment) # design features\n",
    "\n",
    "X_train = experiment['X_train']  # data, numpy array of shape (number of features, number of examples)\n",
    "y_train = experiment['y_train']  # true observations vector of shape (1, number of examples)\n",
    "X_test = experiment['X_test']\n",
    "tau = experiment['tau']\n",
    "N_tau = experiment['N_tau']\n",
    "N_features = experiment['N_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the SPNN parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 50 # number of hidden nodes\n",
    "Lambda = 0.0001 # L2 regularization\n",
    "\n",
    "# loss function parameters (no need to modify)\n",
    "loss_param={\n",
    "    'tau': tau,\n",
    "    'alpha': 0.001,\n",
    "    'kappa': 1e3,\n",
    "    'margin': 0.002\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct and train the SPNN in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add first layer to a sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_dim,\n",
    "                input_dim=N_features,\n",
    "                kernel_initializer='uniform',\n",
    "                kernel_regularizer=regularizers.l2(Lambda),\n",
    "                activation='relu'))\n",
    "\n",
    "# add output layer\n",
    "model.add(Dense(N_tau, kernel_initializer='uniform'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=lambda Y, Q: pinball_loss(y = Y, q = Q, **loss_param), optimizer='Adam')\n",
    "\n",
    "# implement early stopping (to prevent lengthy training)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience = 20, verbose=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0, batch_size=200, callbacks=[es],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict quantiles on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate quantiles of testing data\n",
    "q_hat = model.predict(X_test)\n",
    "q_hat = pd.DataFrame(q_hat, index = X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted quantiles as prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = experiment['y_test']\n",
    "N_PI = experiment['N_PI']\n",
    "    \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test, color='red')\n",
    "x = y_test.index.values\n",
    "for i in range(N_PI):\n",
    "    y1 = q_hat.iloc[:,i]\n",
    "    y2 = q_hat.iloc[:,-1-i]\n",
    "    plt.fill_between(x, y1, y2, color='blue', alpha=str(1/N_PI))\n",
    "plt.ylabel('Normalized Wind Power')\n",
    "plt.xlabel('Time (hour)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
